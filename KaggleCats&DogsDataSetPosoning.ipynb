{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1X6rIMygxJ6MazdVG8EbTJiiUv2_xmqNE",
      "authorship_tag": "ABX9TyOam+5u874tjNa6n3k+Tq1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktcliff/KaggleCats-DogsDataSetPosoning/blob/main/KaggleCats%26DogsDataSetPosoning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential Model Poisoning on 68MB Dataset**"
      ],
      "metadata": {
        "id": "yJNilMXOdfBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lm5__nO2fkFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "qBY7MOvKOJ2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "UZ7eYjURKw7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/drive/MyDrive/Kaggle_API/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "sBW-lCLdKz1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "4FnyxoRgK1Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d samuelcortinhas/cats-and-dogs-image-classification"
      ],
      "metadata": {
        "id": "GRDdVU3QK5Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip cats-and-dogs-image-classification.zip"
      ],
      "metadata": {
        "id": "SbshPu6fK7jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "r-VHC908hB1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the dataset\n",
        "data_dir = '/content/train'\n",
        "\n",
        "# Load the dataset using Keras' image data generator\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "id": "jZkGX1OXwGyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model creation function\n",
        "def create_model(optimizer, activation_param):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation=activation_param, input_shape=(150, 150, 3)),\n",
        "        keras.layers.MaxPooling2D(2, 2),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation=activation_param),\n",
        "        keras.layers.MaxPooling2D(2, 2),\n",
        "        keras.layers.Conv2D(128, (3, 3), activation=activation_param),\n",
        "        keras.layers.MaxPooling2D(2, 2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(512, activation=activation_param),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "SgirX1knyGVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with clean data\n",
        "model = create_model('adam', 'relu')\n",
        "\n",
        "history_clean = model.fit(train_generator,\n",
        "                          epochs=10,\n",
        "                          validation_data=validation_generator)\n",
        "\n",
        "test_score_clean, accuracy_clean = model.evaluate(validation_generator)\n",
        "print(\"Clean Data Model Accuracy: \", accuracy_clean)"
      ],
      "metadata": {
        "id": "WH0j_SK0yLYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation accuracy and loss for clean data\n",
        "acc_clean = history_clean.history['accuracy']\n",
        "val_acc_clean = history_clean.history['val_accuracy']\n",
        "loss_clean = history_clean.history['loss']\n",
        "val_loss_clean = history_clean.history['val_loss']\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc_clean, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc_clean, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy (Clean Data)')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss_clean, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss_clean, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss (Clean Data)')"
      ],
      "metadata": {
        "id": "flrh0qkDyQ_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to poison data\n",
        "def poison_data(generator, target_label, replacement_label, number_to_replace):\n",
        "    count = 0\n",
        "    for i, (images, labels) in enumerate(generator):\n",
        "        for j in range(len(labels)):\n",
        "            if labels[j] == target_label and count < number_to_replace:\n",
        "                labels[j] = replacement_label\n",
        "                count += 1\n",
        "        if count >= number_to_replace:\n",
        "            break\n",
        "    return generator"
      ],
      "metadata": {
        "id": "LK3dJpMnyZQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Poison the data (example: change 200 'dog' labels to 'cat' labels)\n",
        "poisoned_train_generator = poison_data(train_generator, 1, 0, 200)\n",
        "\n",
        "# Training with poisoned data\n",
        "model_poisoned = create_model('adam', 'relu')\n",
        "history_poisoned = model_poisoned.fit(poisoned_train_generator,\n",
        "                                      epochs=10,\n",
        "                                      validation_data=validation_generator)\n",
        "\n",
        "test_score_poisoned, accuracy_poisoned = model_poisoned.evaluate(validation_generator)\n",
        "print(\"Poisoned Data Model Accuracy: \", accuracy_poisoned)"
      ],
      "metadata": {
        "id": "vifXv5JwylB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation accuracy and loss for poisoned data\n",
        "acc_poisoned = history_poisoned.history['accuracy']\n",
        "val_acc_poisoned = history_poisoned.history['val_accuracy']\n",
        "loss_poisoned = history_poisoned.history['loss']\n",
        "val_loss_poisoned = history_poisoned.history['val_loss']\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc_poisoned, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc_poisoned, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy (Poisoned Data)')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss_poisoned, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss_poisoned, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss (Poisoned Data)')"
      ],
      "metadata": {
        "id": "j1BYaHjYy1Ya"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}